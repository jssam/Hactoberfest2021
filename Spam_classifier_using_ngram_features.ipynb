{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam_classifier_using_ngram_features.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L18xZ10irequ",
        "outputId": "4545ce6a-042a-40b6-ba5c-843c3fbb8bc4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7UQpGt1r6iz",
        "outputId": "f566f268-1a7e-4c84-d552-35408595140c"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "57INZ0V6sDB8",
        "outputId": "cd14aeed-5892-4e42-f5d0-758f30691c66"
      },
      "source": [
        "messages = pd.read_csv('/content/drive/My Drive/Dataset/ML_LAB/SMSSpamCollection', sep='\\t', names=[\"label\", \"message\"])\n",
        "messages.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44l9UbyouLnl"
      },
      "source": [
        "import string\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "clean_tweets = []\n",
        "for sentence in messages['message']:\n",
        "    sentence = re.sub(\"[^a-zA-Z0-9]\",\" \",str(sentence))\n",
        "    sentence = re.sub(' +',' ',sentence) #extra spaces\n",
        "    sentence = re.sub(r'\\n',' ',sentence) #non breaking new line characters\n",
        "    sentence = re.sub(r'[^\\w\\s]',' ',sentence)  #remove punctunations\n",
        "    tokens = nltk.word_tokenize(sentence) #tokenization\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in set(stopwords.words('english'))]\n",
        "    #return tokens\n",
        "    tokens = ' '.join(tokens)\n",
        "    clean_tweets.append(tokens)\n",
        "messages['clean_message'] = clean_tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXq5dvmZsOUF",
        "outputId": "e95d3f77-ed57-4495-c8c0-22e4dda3b363"
      },
      "source": [
        "X=messages.clean_message\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "labels = [1 if x == \"spam\" else 0 for x in messages['label'].values]\n",
        "messages['Actual Label'] = labels\n",
        "labels = to_categorical(labels)\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0b3MYTw7zpFX",
        "outputId": "3de02d26-4723-47a7-dec7-8c2c0c2ae41c"
      },
      "source": [
        "messages=messages.dropna()\n",
        "messages.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "      <th>clean_message</th>\n",
              "      <th>Actual Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>U dun say early hor U c already say</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>Nah I think go usf life around though</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ... Actual Label\n",
              "0   ham  ...            0\n",
              "1   ham  ...            0\n",
              "2  spam  ...            1\n",
              "3   ham  ...            0\n",
              "4   ham  ...            0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX7KxZj1vmZW",
        "outputId": "e89ad2a6-263f-41c9-b1a0-11b26cf01078"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td8X3LMIsWFO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X, labels, test_size=0.25, random_state=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xc5FbjUu4RF"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_v=TfidfVectorizer(max_features=5000,ngram_range=(1,1))\n",
        "X_new=tfidf_v.fit_transform(X_train).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg-RoOiGvKFP",
        "outputId": "03a55d04-11d2-4cec-cb9a-1b0958339bb5"
      },
      "source": [
        "print(X_new.shape)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=200, criterion = 'entropy')\n",
        "model.fit(X_new,Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4179, 5000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx1YjeYpwNkE"
      },
      "source": [
        "test_dataset = tfidf_v.transform(X_test)\n",
        "predictions = model.predict(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TqWIvSI31o9",
        "outputId": "f2b1b21f-4500-436f-a57c-03585ecb9ba7"
      },
      "source": [
        "xyz=X_test.to_numpy()\n",
        "xyz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sport fan get latest sport news str 2 ur mobile 1 wk FREE PLUS FREE TONE Txt SPORT ON 8007 www getzed co uk 0870141701216 norm 4txt 120p',\n",
              "       'U reach orchard already U wan 2 go buy ticket first',\n",
              "       'R u continent', ...,\n",
              "       'Hey mr I going sea view couple gay I mean game Give bell ya finish',\n",
              "       'Did u receive msg', 'So pay first lar Then da stock comin'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lMCeFXws2Sj-",
        "outputId": "9b9868d8-3748-4da5-b99a-3db7091cc1a4"
      },
      "source": [
        "df = pd.DataFrame(columns=[\"Cleaned Text\", \"Actual Labels\",\"1-gram\", \"2-gram\",\"3-gram\"], index=range(1393))\n",
        "df[\"Cleaned Text\"]=xyz\n",
        "df[\"Actual Labels\"] = np.argmax(Y_test,axis=1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cleaned Text</th>\n",
              "      <th>Actual Labels</th>\n",
              "      <th>1-gram</th>\n",
              "      <th>2-gram</th>\n",
              "      <th>3-gram</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sport fan get latest sport news str 2 ur mobil...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U reach orchard already U wan 2 go buy ticket ...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>R u continent</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Where download clear movie Dvd copy</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Yes thought Thanks</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Cleaned Text  ...  3-gram\n",
              "0  sport fan get latest sport news str 2 ur mobil...  ...     NaN\n",
              "1  U reach orchard already U wan 2 go buy ticket ...  ...     NaN\n",
              "2                                      R u continent  ...     NaN\n",
              "3                Where download clear movie Dvd copy  ...     NaN\n",
              "4                                 Yes thought Thanks  ...     NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSEEH6RLwXX9",
        "outputId": "ede4499c-ca9a-40b1-e6ec-06d70780a662"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "Y_test=np.argmax(Y_test,axis=1)\n",
        "predictions=np.argmax(predictions,axis=1)\n",
        "df[\"1-gram\"] = predictions\n",
        "matrix=confusion_matrix(Y_test,predictions)\n",
        "print(matrix)\n",
        "score=accuracy_score(Y_test,predictions)\n",
        "print(score)\n",
        "report=classification_report(Y_test,predictions)\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1194    0]\n",
            " [  32  167]]\n",
            "0.9770279971284996\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99      1194\n",
            "           1       1.00      0.84      0.91       199\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.99      0.92      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en1oGUQSw3DG"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_v=TfidfVectorizer(max_features=5000,ngram_range=(2,2))\n",
        "X_new1=tfidf_v.fit_transform(X_train).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPdcaWAxw8Dp",
        "outputId": "6a99598a-2f2d-4c67-9fb7-775c15962f8b"
      },
      "source": [
        "print(X_new1.shape)\n",
        "model.fit(X_new1,Y_train)\n",
        "test_dataset1 = tfidf_v.transform(X_test)\n",
        "predictions = model.predict(test_dataset1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4179, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zCrwEq-xQL1",
        "outputId": "6ad47027-3d77-4d5a-fe3e-32508befd52d"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "predictions=np.argmax(predictions,axis=1)\n",
        "df[\"2-gram\"] = predictions\n",
        "matrix=confusion_matrix(Y_test,predictions)\n",
        "print(matrix)\n",
        "score=accuracy_score(Y_test,predictions)\n",
        "print(score)\n",
        "report=classification_report(Y_test,predictions)\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1193    1]\n",
            " [  55  144]]\n",
            "0.9597989949748744\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98      1194\n",
            "           1       0.99      0.72      0.84       199\n",
            "\n",
            "    accuracy                           0.96      1393\n",
            "   macro avg       0.97      0.86      0.91      1393\n",
            "weighted avg       0.96      0.96      0.96      1393\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEy4c522xzM3"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_v=TfidfVectorizer(max_features=5000,ngram_range=(3,3))\n",
        "X_new2=tfidf_v.fit_transform(X_train).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA2sBYCNx33K"
      },
      "source": [
        "model.fit(X_new2,Y_train)\n",
        "test_dataset2 = tfidf_v.transform(X_test)\n",
        "predictions = model.predict(test_dataset2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liBYlNHNx_s2",
        "outputId": "8bb613dc-08c9-4e93-890e-4e7285c9b023"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "predictions=np.argmax(predictions,axis=1)\n",
        "df[\"3-gram\"] = predictions\n",
        "matrix=confusion_matrix(Y_test,predictions)\n",
        "print(matrix)\n",
        "score=accuracy_score(Y_test,predictions)\n",
        "print(score)\n",
        "report=classification_report(Y_test,predictions)\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1194    0]\n",
            " [  93  106]]\n",
            "0.9332376166547021\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      1194\n",
            "           1       1.00      0.53      0.70       199\n",
            "\n",
            "    accuracy                           0.93      1393\n",
            "   macro avg       0.96      0.77      0.83      1393\n",
            "weighted avg       0.94      0.93      0.92      1393\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_xzV3nE5krH"
      },
      "source": [
        "df.to_csv('/content/drive/My Drive/Dataset/ML_LAB/output.csv', sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}